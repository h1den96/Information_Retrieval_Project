{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh6u3TI0MltHq25FuWlRcH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Εισαγωγή των απαραίτητων βιβλιοθηκών"
      ],
      "metadata": {
        "id": "eSxmZl5G-YZD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLsvhX_81Whk"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1) Εγκατάσταση και εισαγωγή βιβλιοθηκών\n",
        "# ============================================================\n",
        "\n",
        "# Εισαγωγή απαραίτητων βιβλιοθηκών\n",
        "import nltk\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Αρχικοποίηση NLTK"
      ],
      "metadata": {
        "id": "OrilVwVa16Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Λήψη απαραίτητων δεδομένων NLTK (tokenizer, stopwords κ.λπ.)\n",
        "nltk.download('punkt', force=True)\n",
        "nltk.download('stopwords', force=True)\n",
        "nltk.download('wordnet', force=True)\n",
        "\n",
        "# Αρχικοποίηση NLTK components\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"Setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-7o3IE_2Dgf",
        "outputId": "7fbecaf8-24e5-4bd0-a394-7bd908ebbf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Φόρτωση αρχείων\n",
        "\n",
        "Σε αυτή την ενότητα ορίζουμε συναρτήσεις για να φορτώνουμε τα αρχεία JSON (με άρθρα/τίτλους) και το αρχείο CISI.QRY (με queries), έπειτα τα καλούμε για να φορτώσουμε τα δεδομένα μας.\n",
        "\n",
        "Σημειώστε ότι αναμένεται να υπάρχουν τα αρχεία:\n",
        "\n",
        "./wikipedia_articles.json (τα δεδομένα εισόδου που συλλέκτηκαν απο το web crawling στην βικιπαίδεια)\n",
        "\n",
        "./processed_CISI_articles.json (περιέχει μια λίστα άρθρων, όπου το κάθε άρθρο έχει id και μια λίστα από tokens)\n",
        "\n",
        "./CISI_articles.json (το πρωτότυπο αρχείο με πλήρη δεδομένα ή τουλάχιστον τα id και title)\n",
        "\n",
        "./CISI.QRY (τα queries σε φορμά .I <id>, .W, κείμενο ...)"
      ],
      "metadata": {
        "id": "-8IGuRQf4GFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2) Φόρτωση άρθρων, τίτλων, ερωτημάτων\n",
        "# ============================================================\n",
        "\n",
        "def load_articles(json_file):\n",
        "    \"\"\"\n",
        "    Φορτώνει από JSON αρχείο μια λίστα από άρθρα,\n",
        "    όπου κάθε άρθρο είναι λεξικό με κλειδιά:\n",
        "      \"id\", \"tokens\", πιθανώς και άλλα πεδία.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_file, 'r', encoding='utf-8') as file:\n",
        "            return json.load(file)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Σφάλμα: Το αρχείο '{json_file}' δεν βρέθηκε.\")\n",
        "        return []\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Σφάλμα: Μη έγκυρο JSON στο '{json_file}'.\")\n",
        "        return []\n",
        "\n",
        "def load_titles(json_file):\n",
        "    \"\"\"\n",
        "    Φορτώνει από JSON αρχείο μια λίστα articles και φτιάχνει\n",
        "    ένα λεξικό {article_id: article_title}.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(json_file, 'r', encoding='utf-8') as file:\n",
        "            articles = json.load(file)\n",
        "        return {article['id']: article['title'] for article in articles}\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Σφάλμα: Το αρχείο '{json_file}' δεν βρέθηκε.\")\n",
        "        return {}\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Σφάλμα: Μη έγκυρο JSON στο '{json_file}'.\")\n",
        "        return {}\n",
        "\n",
        "def load_queries(file_path):\n",
        "    \"\"\"\n",
        "    Διαβάζει από αρχείο (π.χ. CISI.QRY) τα queries σε φορμά:\n",
        "      .I <query_id>\n",
        "      .W\n",
        "      <query text...>\n",
        "    και επιστρέφει ένα λεξικό { query_id: query_text }.\n",
        "    \"\"\"\n",
        "    queries = {}\n",
        "    current_id = None\n",
        "    query_text = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('.I'):\n",
        "                if current_id is not None:\n",
        "                    queries[current_id] = \" \".join(query_text).strip()\n",
        "                current_id = int(line.split()[1])\n",
        "                query_text = []\n",
        "            elif line.startswith('.W'):\n",
        "                continue\n",
        "            else:\n",
        "                query_text.append(line)\n",
        "        if current_id is not None:\n",
        "            queries[current_id] = \" \".join(query_text).strip()\n",
        "    return queries\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Τώρα καλούμε τις συναρτήσεις για να φορτώσουμε τα αρχεία μας\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "articles_file = './processed_CISI_articles.json'\n",
        "titles_file   = './CISI_articles.json'\n",
        "queries_file  = './CISI.QRY'\n",
        "\n",
        "articles = load_articles(articles_file)\n",
        "title_mapping = load_titles(titles_file)\n",
        "queries = load_queries(queries_file)\n",
        "\n",
        "print(f\"Φορτώθηκαν {len(articles)} άρθρα.\")\n",
        "print(f\"Φορτώθηκαν {len(title_mapping)} τίτλοι άρθρων.\")\n",
        "print(f\"Φορτώθηκαν {len(queries)} queries.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJGsGsUP4QAx",
        "outputId": "a101cba3-bca1-4970-c048-9bc796fd67ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Φορτώθηκαν 1460 άρθρα.\n",
            "Φορτώθηκαν 1460 τίτλοι άρθρων.\n",
            "Φορτώθηκαν 57 queries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x--Oln6O5IGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Σε αυτή την ενότητα δημιουργούμε μια συνάρτηση που κάνει preprocessing (επεξεργασία κειμένου) — αφαιρεί μη αλφαβητικούς χαρακτήρες, κάνει tokenize, αφαιρεί stopwords, εφαρμόζει stemming και lemmatization"
      ],
      "metadata": {
        "id": "H0Pto8Wd7t1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3) Συνάρτηση προεπεξεργασίας κειμένου\n",
        "# ============================================================\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def process_query(text):\n",
        "    \"\"\"\n",
        "    Βήματα:\n",
        "      1) Αφαίρεση μη αλφαβητικών χαρακτήρων\n",
        "      2) Tokenize\n",
        "      3) Lowercase\n",
        "      4) Αφαίρεση stopwords\n",
        "      5) Stemming\n",
        "      6) Lemmatization\n",
        "    \"\"\"\n",
        "    cleaned_text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    tokens = word_tokenize(cleaned_text.lower())\n",
        "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "    stemmed_tokens = [stemmer.stem(w) for w in filtered_tokens]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(w) for w in stemmed_tokens]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή της συνάρτησης\n",
        "# -----------------------------------------------------------\n",
        "sample_text = \"Information retrieval is one of the most important subjects!\"\n",
        "processed_tokens = process_query(sample_text)\n",
        "\n",
        "print(\"Original text: \", sample_text)\n",
        "print(\"Processed tokens: \", processed_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rxFDZN-7vZ_",
        "outputId": "7cadb66d-558e-43ac-fcda-7e7065ac7366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:  Information retrieval is one of the most important subjects!\n",
            "Processed tokens:  ['inform', 'retriev', 'one', 'import', 'subject']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverted Index Implementation\n",
        "Εδώ φτιάχνουμε το inverted index, που είναι ένα λεξικό:\n",
        "token -> [doc_id1, doc_id2, ...],\n",
        "για να γίνει συσχέτιση των όρων και σε ποια documents ανήκουν"
      ],
      "metadata": {
        "id": "MmrC5J1_-wBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4) Υλοποίηση Inverted Index για Boolean Search\n",
        "# ============================================================\n",
        "\n",
        "def buildInvertedIndex(articles):\n",
        "    \"\"\"\n",
        "    Επιστρέφει ένα λεξικό { token: [doc_id1, doc_id2, ...] }.\n",
        "    \"\"\"\n",
        "    inverted_index = defaultdict(list)\n",
        "    for article in articles:\n",
        "        for token in set(article[\"tokens\"]):\n",
        "            inverted_index[token].append(article[\"id\"])\n",
        "    return inverted_index\n",
        "\n",
        "def searchIndex(term, inverted_index):\n",
        "    \"\"\"\n",
        "    Επιστρέφει ένα σύνολο (set) με τα doc_ids για τον όρο 'term'.\n",
        "    Αν δεν υπάρχει ο όρος, επιστρέφει κενό set.\n",
        "    \"\"\"\n",
        "    return set(inverted_index.get(term, []))\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δημιουργία του inverted_index\n",
        "# -----------------------------------------------------------\n",
        "inverted_index = buildInvertedIndex(articles)\n",
        "print(\"Inverted index built.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή στο πρώτο token του sample_text\n",
        "# -----------------------------------------------------------\n",
        "if processed_tokens:\n",
        "    sample_term = processed_tokens[0]\n",
        "    matching_docs = searchIndex(sample_term, inverted_index)\n",
        "    print(f\"Documents containing '{sample_term}': {list(matching_docs)} ...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE01xsdY-yyH",
        "outputId": "aa68ce32-e2be-4b07-a5ce-8fd1fd5800b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverted index built.\n",
            "Documents containing 'inform': [2, 3, 4, 6, 12, 15, 17, 18, 23, 27, 28, 29, 30, 32, 33, 34, 37, 41, 47, 49, 53, 54, 57, 59, 60, 62, 63, 64, 66, 67, 72, 74, 78, 79, 80, 81, 85, 90, 95, 96, 97, 98, 107, 109, 112, 114, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 145, 147, 150, 151, 152, 155, 156, 158, 159, 160, 161, 163, 164, 166, 169, 173, 174, 175, 176, 177, 178, 179, 180, 184, 190, 199, 202, 206, 213, 216, 218, 220, 224, 225, 228, 231, 236, 241, 243, 244, 245, 248, 252, 254, 257, 258, 259, 260, 267, 270, 274, 293, 309, 310, 311, 314, 319, 320, 321, 323, 324, 327, 328, 330, 334, 336, 338, 339, 340, 341, 344, 345, 346, 347, 348, 352, 360, 362, 363, 367, 371, 372, 373, 375, 376, 378, 381, 386, 388, 389, 392, 398, 400, 403, 406, 408, 411, 412, 419, 420, 421, 425, 426, 429, 433, 434, 439, 440, 442, 444, 445, 446, 449, 451, 452, 453, 454, 456, 458, 459, 460, 461, 462, 463, 466, 469, 471, 473, 474, 475, 476, 477, 478, 480, 481, 484, 486, 487, 488, 490, 496, 497, 501, 502, 504, 505, 509, 512, 513, 514, 515, 516, 518, 523, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 539, 540, 542, 544, 545, 546, 547, 553, 554, 556, 557, 560, 563, 565, 566, 567, 568, 572, 574, 575, 577, 578, 580, 582, 583, 584, 585, 588, 589, 590, 591, 592, 593, 594, 598, 599, 602, 604, 606, 607, 611, 612, 615, 616, 618, 619, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 633, 636, 637, 639, 640, 641, 642, 644, 646, 648, 652, 655, 656, 657, 658, 660, 661, 664, 665, 670, 671, 672, 674, 675, 676, 678, 679, 680, 682, 684, 686, 687, 690, 692, 694, 695, 701, 703, 704, 705, 707, 711, 712, 716, 717, 718, 719, 721, 722, 723, 728, 730, 733, 736, 737, 743, 755, 761, 762, 763, 764, 769, 770, 771, 772, 773, 783, 784, 786, 790, 796, 797, 798, 799, 801, 803, 807, 809, 811, 813, 814, 815, 816, 817, 819, 820, 821, 826, 828, 829, 835, 837, 839, 842, 844, 845, 846, 848, 850, 851, 853, 865, 866, 878, 883, 885, 889, 895, 898, 899, 900, 901, 907, 908, 910, 916, 922, 924, 925, 930, 935, 937, 941, 942, 946, 947, 948, 951, 955, 956, 957, 958, 963, 964, 965, 966, 967, 970, 971, 972, 981, 982, 984, 986, 990, 993, 1009, 1010, 1011, 1012, 1013, 1018, 1022, 1027, 1032, 1035, 1037, 1038, 1042, 1047, 1051, 1053, 1054, 1055, 1057, 1059, 1076, 1077, 1078, 1080, 1081, 1084, 1089, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1128, 1129, 1130, 1132, 1134, 1136, 1138, 1139, 1142, 1143, 1144, 1145, 1146, 1149, 1151, 1153, 1155, 1156, 1158, 1160, 1161, 1162, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1189, 1190, 1191, 1192, 1196, 1198, 1201, 1207, 1208, 1209, 1220, 1223, 1224, 1227, 1231, 1241, 1244, 1245, 1248, 1253, 1255, 1256, 1258, 1263, 1264, 1265, 1266, 1281, 1283, 1289, 1293, 1295, 1297, 1298, 1299, 1303, 1305, 1309, 1318, 1323, 1326, 1335, 1341, 1347, 1348, 1349, 1350, 1356, 1358, 1361, 1362, 1364, 1367, 1368, 1370, 1373, 1378, 1382, 1390, 1391, 1392, 1396, 1401, 1404, 1405, 1407, 1408, 1410, 1411, 1412, 1413, 1415, 1419, 1421, 1426, 1427, 1428, 1431, 1435, 1436, 1437, 1442, 1446, 1447, 1460] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8HvIDbXABXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boolean Search Implementation\n",
        "\n",
        "Τώρα χτίζουμε τη λογική για Boolean Expressions τύπου information AND system, information OR system, information NOT system κ.λπ. Κάνουμε parsing της έκφρασης και χρησιμοποιούμε σύνολα για AND/OR/NOT.\n"
      ],
      "metadata": {
        "id": "k7k0K2mEAsAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5) Boolean Search\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_expression(expression, articles):\n",
        "    \"\"\"\n",
        "    Υλοποιεί τη Boolean αναζήτηση που υποστηρίζει AND, OR, NOT.\n",
        "    Κάνει tokenize στην έκφραση, και χρησιμοποιεί μια στοίβα για\n",
        "    αξιολόγηση (βασική postfix/stack λογική).\n",
        "    \"\"\"\n",
        "    stack = []\n",
        "    tokens = expression.split()\n",
        "    for token in tokens:\n",
        "        token_up = token.upper()\n",
        "        if token_up in {\"AND\", \"OR\", \"NOT\"}:\n",
        "            stack.append(token_up)\n",
        "        else:\n",
        "            matching = searchIndex(token, articles)\n",
        "            stack.append(matching)\n",
        "        # Όταν έχουμε σχήμα [SET, 'AND/OR/NOT', SET] το αξιολογούμε\n",
        "        while len(stack) >= 3 and isinstance(stack[-1], set) and isinstance(stack[-3], set):\n",
        "            right = stack.pop()\n",
        "            operator = stack.pop()\n",
        "            left = stack.pop()\n",
        "\n",
        "            if operator == \"AND\":\n",
        "                stack.append(left & right)\n",
        "            elif operator == \"OR\":\n",
        "                stack.append(left | right)\n",
        "            elif operator == \"NOT\":\n",
        "                stack.append(left - right)\n",
        "\n",
        "    if len(stack) == 1 and isinstance(stack[0], set):\n",
        "        return stack[0]\n",
        "    else:\n",
        "        return set()\n",
        "\n",
        "def boolean_search(query_text, articles):\n",
        "    \"\"\"\n",
        "    Επιστρέφει μια λίστα από doc_ids που ταιριάζουν στη Boolean έκφραση.\n",
        "    Σε περίπτωση που αποτύχει η parsing (λχ λάθος syntax), πέφτει στο \"fallback OR\".\n",
        "    \"\"\"\n",
        "    query_text = query_text.strip()\n",
        "    try:\n",
        "        result_set = evaluate_expression(query_text, articles)\n",
        "        if not result_set:\n",
        "            raise ValueError(\"Empty result from Boolean\")\n",
        "        return list(result_set), []\n",
        "    except:\n",
        "        # fallback: αν δεν δουλέψει η έκφραση, κάνουμε OR σε όλα τα tokens\n",
        "        processed = process_query(query_text)\n",
        "        results = set()\n",
        "        for t in processed:\n",
        "            results.update(searchIndex(t, articles))\n",
        "        return list(results), []\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή Boolean Search\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "test_query = \"information\"\n",
        "results_boolean = boolean_search(test_query, inverted_index)\n",
        "print(f\"Results for query '{test_query}': {results_boolean} ...\")\n",
        "\n",
        "test_query = \"system\"\n",
        "results_boolean = boolean_search(test_query, inverted_index)\n",
        "print(f\"Results for query '{test_query}': {results_boolean} ...\")\n",
        "\n",
        "test_query = \"information AND system\"\n",
        "results_boolean = boolean_search(test_query, inverted_index)\n",
        "print(f\"Results for query '{test_query}': {results_boolean} ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYEbUuUTAyg_",
        "outputId": "3b822996-7039-477b-ca18-f808246cd288"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for query 'information': ([2, 3, 4, 6, 12, 15, 17, 18, 23, 27, 28, 29, 30, 32, 33, 34, 37, 41, 47, 49, 53, 54, 57, 59, 60, 62, 63, 64, 66, 67, 72, 74, 78, 79, 80, 81, 85, 90, 95, 96, 97, 98, 107, 109, 112, 114, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 145, 147, 150, 151, 152, 155, 156, 158, 159, 160, 161, 163, 164, 166, 169, 173, 174, 175, 176, 177, 178, 179, 180, 184, 190, 199, 202, 206, 213, 216, 218, 220, 224, 225, 228, 231, 236, 241, 243, 244, 245, 248, 252, 254, 257, 258, 259, 260, 267, 270, 274, 293, 309, 310, 311, 314, 319, 320, 321, 323, 324, 327, 328, 330, 334, 336, 338, 339, 340, 341, 344, 345, 346, 347, 348, 352, 360, 362, 363, 367, 371, 372, 373, 375, 376, 378, 381, 386, 388, 389, 392, 398, 400, 403, 406, 408, 411, 412, 419, 420, 421, 425, 426, 429, 433, 434, 439, 440, 442, 444, 445, 446, 449, 451, 452, 453, 454, 456, 458, 459, 460, 461, 462, 463, 466, 469, 471, 473, 474, 475, 476, 477, 478, 480, 481, 484, 486, 487, 488, 490, 496, 497, 501, 502, 504, 505, 509, 512, 513, 514, 515, 516, 518, 523, 525, 526, 528, 529, 532, 533, 534, 535, 536, 537, 538, 539, 540, 542, 544, 545, 546, 547, 553, 554, 556, 557, 560, 563, 565, 566, 567, 568, 572, 574, 575, 577, 578, 580, 582, 583, 584, 585, 588, 589, 590, 591, 592, 593, 594, 598, 599, 602, 604, 606, 607, 611, 612, 615, 616, 618, 619, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 633, 636, 637, 639, 640, 641, 642, 644, 646, 648, 652, 655, 656, 657, 658, 660, 661, 664, 665, 670, 671, 672, 674, 675, 676, 678, 679, 680, 682, 684, 686, 687, 690, 692, 694, 695, 701, 703, 704, 705, 707, 711, 712, 716, 717, 718, 719, 721, 722, 723, 728, 730, 733, 736, 737, 743, 755, 761, 762, 763, 764, 769, 770, 771, 772, 773, 783, 784, 786, 790, 796, 797, 798, 799, 801, 803, 807, 809, 811, 813, 814, 815, 816, 817, 819, 820, 821, 826, 828, 829, 835, 837, 839, 842, 844, 845, 846, 848, 850, 851, 853, 865, 866, 878, 883, 885, 889, 895, 898, 899, 900, 901, 907, 908, 910, 916, 922, 924, 925, 930, 935, 937, 941, 942, 946, 947, 948, 951, 955, 956, 957, 958, 963, 964, 965, 966, 967, 970, 971, 972, 981, 982, 984, 986, 990, 993, 1009, 1010, 1011, 1012, 1013, 1018, 1022, 1027, 1032, 1035, 1037, 1038, 1042, 1047, 1051, 1053, 1054, 1055, 1057, 1059, 1076, 1077, 1078, 1080, 1081, 1084, 1089, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1128, 1129, 1130, 1132, 1134, 1136, 1138, 1139, 1142, 1143, 1144, 1145, 1146, 1149, 1151, 1153, 1155, 1156, 1158, 1160, 1161, 1162, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1189, 1190, 1191, 1192, 1196, 1198, 1201, 1207, 1208, 1209, 1220, 1223, 1224, 1227, 1231, 1241, 1244, 1245, 1248, 1253, 1255, 1256, 1258, 1263, 1264, 1265, 1266, 1281, 1283, 1289, 1293, 1295, 1297, 1298, 1299, 1303, 1305, 1309, 1318, 1323, 1326, 1335, 1341, 1347, 1348, 1349, 1350, 1356, 1358, 1361, 1362, 1364, 1367, 1368, 1370, 1373, 1378, 1382, 1390, 1391, 1392, 1396, 1401, 1404, 1405, 1407, 1408, 1410, 1411, 1412, 1413, 1415, 1419, 1421, 1426, 1427, 1428, 1431, 1435, 1436, 1437, 1442, 1446, 1447, 1460], []) ...\n",
            "Results for query 'system': ([1, 10, 13, 16, 17, 18, 25, 27, 28, 44, 48, 49, 54, 57, 59, 61, 64, 66, 67, 68, 71, 72, 73, 74, 80, 85, 89, 95, 102, 104, 106, 114, 115, 117, 119, 120, 123, 126, 128, 129, 131, 132, 134, 135, 136, 137, 140, 141, 150, 151, 158, 159, 165, 168, 174, 175, 177, 179, 180, 190, 192, 197, 200, 202, 208, 211, 213, 222, 224, 228, 231, 244, 245, 250, 252, 254, 257, 262, 265, 267, 268, 287, 288, 291, 292, 294, 309, 310, 317, 319, 320, 325, 327, 329, 332, 335, 336, 340, 347, 348, 350, 354, 358, 364, 373, 375, 376, 378, 380, 381, 382, 386, 387, 388, 389, 394, 396, 398, 399, 400, 403, 406, 408, 409, 419, 421, 433, 434, 443, 445, 446, 447, 448, 449, 451, 452, 454, 458, 459, 461, 465, 467, 468, 472, 474, 476, 477, 478, 481, 482, 483, 484, 486, 490, 491, 492, 497, 501, 502, 504, 507, 508, 510, 511, 512, 513, 514, 515, 517, 519, 522, 523, 525, 526, 528, 529, 530, 531, 532, 534, 535, 537, 538, 542, 544, 546, 547, 553, 556, 557, 560, 562, 564, 565, 566, 567, 571, 572, 574, 575, 576, 579, 582, 590, 591, 593, 594, 595, 597, 600, 601, 603, 606, 607, 609, 610, 611, 612, 615, 617, 620, 621, 625, 626, 627, 630, 634, 636, 637, 639, 641, 642, 644, 645, 646, 647, 648, 652, 654, 659, 660, 664, 666, 670, 671, 674, 676, 677, 682, 683, 687, 689, 690, 693, 694, 695, 697, 699, 700, 701, 702, 703, 704, 706, 707, 709, 710, 716, 720, 723, 724, 725, 726, 727, 728, 731, 737, 739, 740, 741, 742, 744, 752, 754, 762, 773, 779, 780, 785, 786, 795, 796, 798, 801, 802, 806, 809, 815, 820, 822, 825, 826, 827, 830, 833, 838, 839, 840, 841, 842, 843, 846, 848, 849, 850, 852, 860, 862, 865, 866, 868, 871, 872, 874, 880, 883, 884, 888, 889, 890, 895, 897, 898, 911, 916, 917, 925, 941, 947, 948, 951, 954, 955, 960, 966, 970, 979, 982, 984, 986, 989, 990, 993, 997, 998, 999, 1000, 1001, 1004, 1007, 1010, 1011, 1012, 1016, 1022, 1024, 1035, 1038, 1040, 1043, 1044, 1049, 1051, 1053, 1054, 1057, 1062, 1067, 1073, 1074, 1077, 1078, 1080, 1081, 1084, 1085, 1091, 1092, 1093, 1098, 1099, 1104, 1105, 1106, 1109, 1110, 1111, 1112, 1114, 1117, 1120, 1121, 1124, 1125, 1126, 1127, 1128, 1136, 1137, 1139, 1143, 1144, 1147, 1148, 1152, 1163, 1170, 1171, 1173, 1175, 1179, 1180, 1190, 1191, 1193, 1195, 1196, 1197, 1207, 1209, 1215, 1223, 1225, 1227, 1229, 1230, 1236, 1241, 1249, 1255, 1256, 1259, 1261, 1264, 1267, 1277, 1281, 1283, 1290, 1293, 1298, 1305, 1309, 1317, 1326, 1327, 1328, 1333, 1337, 1339, 1341, 1348, 1349, 1350, 1358, 1360, 1361, 1362, 1363, 1366, 1367, 1375, 1377, 1378, 1391, 1395, 1405, 1409, 1410, 1413, 1415, 1416, 1417, 1418, 1419, 1425, 1427, 1436, 1437, 1445, 1447, 1448, 1456, 1457], []) ...\n",
            "Results for query 'information AND system': ([1, 2, 3, 4, 6, 10, 12, 13, 15, 16, 17, 18, 23, 25, 27, 28, 29, 30, 32, 33, 34, 37, 41, 44, 47, 48, 49, 53, 54, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 74, 78, 79, 80, 81, 85, 89, 90, 95, 96, 97, 98, 102, 104, 106, 107, 109, 112, 114, 115, 117, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 145, 147, 150, 151, 152, 155, 156, 158, 159, 160, 161, 163, 164, 165, 166, 168, 169, 173, 174, 175, 176, 177, 178, 179, 180, 184, 190, 192, 197, 199, 200, 202, 206, 208, 211, 213, 216, 218, 220, 222, 224, 225, 228, 231, 236, 241, 243, 244, 245, 248, 250, 252, 254, 257, 258, 259, 260, 262, 265, 267, 268, 270, 274, 287, 288, 291, 292, 293, 294, 309, 310, 311, 314, 317, 319, 320, 321, 323, 324, 325, 327, 328, 329, 330, 332, 334, 335, 336, 338, 339, 340, 341, 344, 345, 346, 347, 348, 350, 352, 354, 358, 360, 362, 363, 364, 367, 371, 372, 373, 375, 376, 378, 380, 381, 382, 386, 387, 388, 389, 392, 394, 396, 398, 399, 400, 403, 406, 408, 409, 411, 412, 419, 420, 421, 425, 426, 429, 433, 434, 439, 440, 442, 443, 444, 445, 446, 447, 448, 449, 451, 452, 453, 454, 456, 458, 459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 480, 481, 482, 483, 484, 486, 487, 488, 490, 491, 492, 496, 497, 501, 502, 504, 505, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 522, 523, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 542, 544, 545, 546, 547, 553, 554, 556, 557, 560, 562, 563, 564, 565, 566, 567, 568, 571, 572, 574, 575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 588, 589, 590, 591, 592, 593, 594, 595, 597, 598, 599, 600, 601, 602, 603, 604, 606, 607, 609, 610, 611, 612, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 633, 634, 636, 637, 639, 640, 641, 642, 644, 645, 646, 647, 648, 652, 654, 655, 656, 657, 658, 659, 660, 661, 664, 665, 666, 670, 671, 672, 674, 675, 676, 677, 678, 679, 680, 682, 683, 684, 686, 687, 689, 690, 692, 693, 694, 695, 697, 699, 700, 701, 702, 703, 704, 705, 706, 707, 709, 710, 711, 712, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 730, 731, 733, 736, 737, 739, 740, 741, 742, 743, 744, 752, 754, 755, 761, 762, 763, 764, 769, 770, 771, 772, 773, 779, 780, 783, 784, 785, 786, 790, 795, 796, 797, 798, 799, 801, 802, 803, 806, 807, 809, 811, 813, 814, 815, 816, 817, 819, 820, 821, 822, 825, 826, 827, 828, 829, 830, 833, 835, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 848, 849, 850, 851, 852, 853, 860, 862, 865, 866, 868, 871, 872, 874, 878, 880, 883, 884, 885, 888, 889, 890, 895, 897, 898, 899, 900, 901, 907, 908, 910, 911, 916, 917, 922, 924, 925, 930, 935, 937, 941, 942, 946, 947, 948, 951, 954, 955, 956, 957, 958, 960, 963, 964, 965, 966, 967, 970, 971, 972, 979, 981, 982, 984, 986, 989, 990, 993, 997, 998, 999, 1000, 1001, 1004, 1007, 1009, 1010, 1011, 1012, 1013, 1016, 1018, 1022, 1024, 1027, 1032, 1035, 1037, 1038, 1040, 1042, 1043, 1044, 1047, 1049, 1051, 1053, 1054, 1055, 1057, 1059, 1062, 1067, 1073, 1074, 1076, 1077, 1078, 1080, 1081, 1084, 1085, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1132, 1134, 1136, 1137, 1138, 1139, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1155, 1156, 1158, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1189, 1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1201, 1207, 1208, 1209, 1215, 1220, 1223, 1224, 1225, 1227, 1229, 1230, 1231, 1236, 1241, 1244, 1245, 1248, 1249, 1253, 1255, 1256, 1258, 1259, 1261, 1263, 1264, 1265, 1266, 1267, 1277, 1281, 1283, 1289, 1290, 1293, 1295, 1297, 1298, 1299, 1303, 1305, 1309, 1317, 1318, 1323, 1326, 1327, 1328, 1333, 1335, 1337, 1339, 1341, 1347, 1348, 1349, 1350, 1356, 1358, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1370, 1373, 1375, 1377, 1378, 1382, 1390, 1391, 1392, 1395, 1396, 1401, 1404, 1405, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1418, 1419, 1421, 1425, 1426, 1427, 1428, 1431, 1435, 1436, 1437, 1442, 1445, 1446, 1447, 1448, 1456, 1457, 1460], []) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZpEMTGQA1VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Implementation (Dot Product)\n",
        "Τώρα θα υλοποιήσουμε μια απλή TF-IDF προσέγγιση, χρησιμοποιώντας TfidfVectorizer από το scikit-learn. Υπολογίζουμε τον πίνακα TF-IDF για όλα τα άρθρα και κάνουμε dot-product με το query vector.\n"
      ],
      "metadata": {
        "id": "AXcLkfUDA_4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 6) TF-IDF (dot product)\n",
        "# ============================================================\n",
        "\n",
        "def rank_tfidf(query_tokens, articles, inverted_index):\n",
        "    # 1) Βρίσκουμε τα σχετικά έγγραφα (doc_ids) από το inverted index\n",
        "    relevant_doc_ids = set()\n",
        "    for token in query_tokens:\n",
        "        relevant_doc_ids.update(inverted_index.get(token, []))\n",
        "\n",
        "    # 2) Φτιάχνουμε ένα υποσύνολο των άρθρων\n",
        "    relevant_docs = [a for a in articles if a['id'] in relevant_doc_ids]\n",
        "\n",
        "    # 3) Δημιουργούμε το document-term matrix (TF-IDF) για αυτά τα docs\n",
        "    corpus = [\" \".join(a['tokens']) for a in relevant_docs]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    # 4) Μετατρέπουμε το query σε vector μέσω του ίδιου vectorizer\n",
        "    query_vec = vectorizer.transform([\" \".join(query_tokens)])\n",
        "\n",
        "    # 5) Υπολογίζουμε το dot product (tfidf_matrix * query_vec)\n",
        "    scores = (tfidf_matrix @ query_vec.T).toarray().flatten()\n",
        "    # Το πολλαπλασιάζουμε επί 100 για κλίμακα 0-100\n",
        "    scores *= 100\n",
        "\n",
        "    # 6) Ταξινομούμε φθίνουσα\n",
        "    ranked_indices = np.argsort(-scores)\n",
        "    # Εξάγουμε doc_ids και scores\n",
        "    ranked_docs = [relevant_docs[i]['id'] for i in ranked_indices]\n",
        "    ranked_scores = [scores[i] for i in ranked_indices]\n",
        "    return ranked_docs, ranked_scores\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή\n",
        "# -----------------------------------------------------------\n",
        "query_text = \"information retrieval systems\"\n",
        "test_query_tokens = process_query(query_text)\n",
        "ranked_indices_tfidf, scores_tfidf = rank_tfidf(test_query_tokens, articles, inverted_index) # Added inverted_index as an argument\n",
        "\n",
        "print(f\"Top 5 document indices using TF-IDF for query: {query_text}\")\n",
        "for i in ranked_indices_tfidf[:5]:\n",
        "    # Βρίσκουμε το index του άρθρου που αντιστοιχεί στο doc ID\n",
        "    article_index = next((index for index, article in enumerate(articles) if article['id'] == i), None)\n",
        "    if article_index is not None:  # Αν βρέθηκε το άρθρο\n",
        "        print(f\"Doc index = {i}, Score = {scores_tfidf[ranked_indices_tfidf.index(i)]:.2f}, ID = {articles[article_index]['id']}\")\n",
        "    else:\n",
        "        print(f\"Article with ID {i} not found in the articles list.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7lnkgMaBFuK",
        "outputId": "8f3d9903-95c0-4958-b64f-9fd64e60c47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 document indices using TF-IDF for query: information retrieval systems\n",
            "Doc index = 565, Score = 47.77, ID = 565\n",
            "Doc index = 1136, Score = 46.01, ID = 1136\n",
            "Doc index = 459, Score = 34.52, ID = 459\n",
            "Doc index = 458, Score = 33.15, ID = 458\n",
            "Doc index = 538, Score = 32.95, ID = 538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuKaqKDIBJ88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BM25 Implementation\n",
        "Η BM25 είναι μια πιο εξελιγμένη μέθοδος που στηρίζεται σε TF, IDF και μήκος εγγράφου. Παρακάτω την υλοποιούμε σε δύο βήματα:\n",
        "\n",
        "1. calc_idf για BM25\n",
        "2. BM25 συνάρτηση που υπολογίζει το score κάθε εγγράφου"
      ],
      "metadata": {
        "id": "NTQfN947CQHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# BM25\n",
        "# ---------------------------------------------------------\n",
        "\"\"\"\n",
        "Η μέθοδος BM25 είναι ένας αλγόριθμος ranking που βασίζεται σε TF, IDF\n",
        "και σε δύο παραμέτρους (k1 και b). Υπολογίζει για κάθε όρο q και έγγραφο d:\n",
        "  score(d) += IDF(q) * ( (TF(q,d)*(k1+1)) / (TF(q,d) + k1*(1 - b + b*(|d|/avg|d|))) )\n",
        "\"\"\"\n",
        "def calc_idf(articles):\n",
        "    # Υπολογισμός idf για BM25: log( (N - df + 0.5)/(df + 0.5) + 1 )\n",
        "    N = len(articles)\n",
        "    term_doc_count = defaultdict(int)\n",
        "    for article in articles:\n",
        "        unique_tokens = set(article['tokens'])\n",
        "        for token in unique_tokens:\n",
        "            term_doc_count[token] += 1\n",
        "    idf = {}\n",
        "    for token, doc_count in term_doc_count.items():\n",
        "        idf[token] = math.log((N - doc_count + 0.5) / (doc_count + 0.5) + 1)\n",
        "    return idf\n",
        "\n",
        "def rank_bm25(query_tokens, articles, idf, inverted_index):\n",
        "    \"\"\"\n",
        "    Βρίσκουμε πάλι μόνο τα σχετικά έγγραφα από το inverted index, κι\n",
        "    έπειτα υπολογίζουμε το BM25 score για το καθένα βάσει TF, IDF, k1, b.\n",
        "    \"\"\"\n",
        "    k1 = 1.5\n",
        "    b = 0.75\n",
        "    N = len(articles)\n",
        "    avg_len = sum(len(a['tokens']) for a in articles) / N\n",
        "\n",
        "    # 1) σχετικά doc_ids\n",
        "    relevant_doc_ids = set()\n",
        "    for token in query_tokens:\n",
        "        relevant_doc_ids.update(inverted_index.get(token, []))\n",
        "\n",
        "    # 2) Φτιάχνουμε τη λίστα των relevant_docs\n",
        "    relevant_docs = [a for a in articles if a['id'] in relevant_doc_ids]\n",
        "\n",
        "    # 3) Υπολογισμός BM25 score\n",
        "    scores = []\n",
        "    for a in relevant_docs:\n",
        "        freq = defaultdict(int)\n",
        "        for t in a['tokens']:\n",
        "            freq[t] += 1\n",
        "\n",
        "        score = 0\n",
        "        for q in query_tokens:\n",
        "            if q in idf:\n",
        "                tf = freq[q]\n",
        "                numerator = tf * (k1 + 1)\n",
        "                denominator = tf + k1 * (1 - b + b * (len(a['tokens']) / avg_len))\n",
        "                score += idf[q] * (numerator / denominator)\n",
        "\n",
        "        scores.append(score)\n",
        "\n",
        "    scores = np.array(scores)\n",
        "    # Ταξινόμηση\n",
        "    ranked_indices = np.argsort(-scores)\n",
        "    ranked_docs = [relevant_docs[i]['id'] for i in ranked_indices]\n",
        "    ranked_scores = [scores[i] for i in ranked_indices]\n",
        "    return ranked_docs, ranked_scores\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Υπολογίζουμε τα idf_values μια φορά\n",
        "# -----------------------------------------------------------\n",
        "idf_values = calc_idf(articles)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή BM25\n",
        "# -----------------------------------------------------------\n",
        "ranked_indices_bm25, scores_bm25 = rank_bm25(test_query_tokens, articles, idf_values, inverted_index)\n",
        "print(f\"Top 5 document indices using BM25 for query: {query_text}\")\n",
        "for doc_index in ranked_indices_bm25[:5]:\n",
        "    article_index = next((index for index, article in enumerate(articles) if article['id'] == doc_index), None)\n",
        "\n",
        "    if article_index is not None:\n",
        "        print(f\"Doc index = {doc_index}, Score = {scores_bm25[ranked_indices_bm25.index(doc_index)]:.2f}, ID = {articles[article_index]['id']}\")\n",
        "    else:\n",
        "        print(f\"Article with ID {doc_index} not found in the articles list.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-x85LDpCUNN",
        "outputId": "b7f3a9ce-5203-4daa-ff44-d0c469840b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 document indices using BM25 for query: information retrieval systems\n",
            "Doc index = 1136, Score = 7.12, ID = 1136\n",
            "Doc index = 565, Score = 7.09, ID = 565\n",
            "Doc index = 459, Score = 6.52, ID = 459\n",
            "Doc index = 445, Score = 6.52, ID = 445\n",
            "Doc index = 611, Score = 6.38, ID = 611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Space Model\n",
        "Στο μοντέλο διανυσματικού χώρου (VSM), κάθε έγγραφο ή ερώτημα είναι ένα διάνυσμα Ν-διαστάσεων, όπου Ν είναι ο αριθμός των διαφορετικών όρων σε όλα τα έγγραφα και τα ερωτήματα.Ο i-οστός δείκτης ενός διανύσματος περιέχει τη βαθμολογία του i-οστού όρου για το συγκεκριμένο διάνυσμα. Χρησιμοποιούνται TF-IDF και Cosine Similarity."
      ],
      "metadata": {
        "id": "1G80DrzNI-Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TF-IDF + Cosine Similarity\n",
        "# ============================================================\n",
        "def rank_vsm(query_tokens, articles, inverted_index):\n",
        "    \"\"\"\n",
        "    Υλοποιεί αναζήτηση βασισμένη σε TF-IDF και Cosine Similarity,\n",
        "    μόνο για έγγραφα που περιέχουν τουλάχιστον έναν από τους όρους του query.\n",
        "\n",
        "    Βήματα:\n",
        "    1) Εύρεση συναφών εγγράφων (relevant_docs) μέσω του inverted_index.\n",
        "    2) Δημιουργία TF-IDF matrix μόνο για αυτά τα έγγραφα.\n",
        "    3) Δημιουργία vector για το query.\n",
        "    4) Υπολογισμός cosine_similarity.\n",
        "    5) Κανονικοποίηση των scores σε 0..100.\n",
        "    6) Επιστροφή ταξινομημένης λίστας doc_ids και των αντίστοιχων scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Εύρεση relevant_doc_ids\n",
        "    relevant_doc_ids = set()\n",
        "    for token in query_tokens:\n",
        "        relevant_doc_ids.update(inverted_index.get(token, []))\n",
        "\n",
        "    # 2) Φιλτράρουμε τα articles για να κρατήσουμε μόνο τα σχετικά\n",
        "    relevant_docs = [a for a in articles if a['id'] in relevant_doc_ids]\n",
        "\n",
        "    # 3) Δημιουργούμε ένα corpus για το TfidfVectorizer\n",
        "    corpus = [\" \".join(a['tokens']) for a in relevant_docs]\n",
        "\n",
        "    # Check if the corpus is empty after preprocessing\n",
        "    if not any(corpus):\n",
        "        print(\"Warning: Corpus is empty after preprocessing. Returning empty results.\")\n",
        "        return [], [] # Return empty lists to indicate no results\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    # 4) Φτιάχνουμε το query vector\n",
        "    query_vec = vectorizer.transform([\" \".join(query_tokens)])\n",
        "\n",
        "    # 5) Υπολογίζουμε cosine similarity\n",
        "    cos_sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "\n",
        "    # 6) Κλίμακα 0..100\n",
        "    cos_sims *= 100\n",
        "\n",
        "    # 7) Ταξινόμηση φθίνουσα\n",
        "    ranked_indices = np.argsort(-cos_sims)\n",
        "    ranked_docs = [relevant_docs[i]['id'] for i in ranked_indices]\n",
        "    ranked_scores = [cos_sims[i] for i in ranked_indices]\n",
        "\n",
        "    return ranked_docs, ranked_scores\n",
        "\n",
        "test_query_tokens = [\"quick\", \"history\"]\n",
        "docs_vsm, scores_vsm = rank_vsm(test_query_tokens, articles, inverted_index)\n",
        "print(\"Top 5 Docs (TF-IDF + Cosine):\", docs_vsm[:5])\n",
        "print(\"Scores:\", scores_vsm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4qu3-fYJYRt",
        "outputId": "afc4022e-2b7b-4d1e-d6bb-f53ae7cda6d5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Docs (TF-IDF + Cosine): [174, 928]\n",
            "Scores: [6.561619460946319, 3.592972573809947]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Συνάρτηση Ranking\n",
        "Σε αυτή τη φάση, ενώνουμε τις διάφορες μεθόδους (Boolean, TF-IDF, BM25, TF-IDF+Cosine) σε μία κεντρική συνάρτηση ranking"
      ],
      "metadata": {
        "id": "REzrCfwhISDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Συνάρτηση Ranking (με 4 methods)\n",
        "# ============================================================\n",
        "\n",
        "def ranking(articles, query_text, method, inverted_index):\n",
        "    \"\"\"\n",
        "    Ανάλογα με το 'method':\n",
        "      '1' -> Boolean\n",
        "      '2' -> TF-IDF (dot product)\n",
        "      '3' -> BM25\n",
        "      '4' -> TF-IDF + Cosine\n",
        "    \"\"\"\n",
        "    # Προεπεξεργασία του query\n",
        "    processed_query = process_query(query_text)\n",
        "\n",
        "    if method == '1':\n",
        "        # Boolean\n",
        "        docs, _ = boolean_search(query_text, inverted_index)\n",
        "        return docs, []\n",
        "\n",
        "    elif method == '2':\n",
        "        # TF-IDF (dot product)\n",
        "        # π.χ. θα χρησιμοποιήσουμε rank_tfidf_vectorizer\n",
        "        ranked_indices, sc = rank_tfidf(processed_query, articles, inverted_index)\n",
        "        # ranked_indices είναι λίστα από doc_ids, όχι indices\n",
        "        #doc_ids = [articles[i]['id'] for i in ranked_indices] # This line is removed\n",
        "        doc_ids = ranked_indices # ranked_indices already contain doc_ids\n",
        "        scores_ordered = [sc[i] for i in range(len(ranked_indices))] # Using a range of indices\n",
        "        return doc_ids, scores_ordered\n",
        "\n",
        "    elif method == '3':\n",
        "        # BM25\n",
        "        idf_vals = calc_idf(articles)\n",
        "        doc_ids, scores_ordered = rank_bm25(processed_query, articles, idf_vals, inverted_index) # Added inverted_index\n",
        "        return doc_ids, scores_ordered\n",
        "\n",
        "    elif method == '4':\n",
        "        # TF-IDF + Cosine\n",
        "        doc_ids, scores_ordered = rank_vsm(processed_query, articles, inverted_index) # Added inverted_index, removed relevant_only\n",
        "        return doc_ids, scores_ordered\n",
        "\n",
        "    else:\n",
        "        print(\"Μη έγκυρη μέθοδος.\")\n",
        "        return [], []\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή της ranking() συνάρτησης\n",
        "# -----------------------------------------------------------\n",
        "test_query2 = \"information science\"\n",
        "for m in ['1','2','3','4']:\n",
        "    doc_list, scores = ranking(articles, test_query2, m, inverted_index)\n",
        "    print(f\"Method={m}, first 5 results:\")\n",
        "    for i in range(min(5, len(doc_list))):\n",
        "        did = doc_list[i]\n",
        "        sc  = scores[i] if scores else 0\n",
        "        print(f\"  DocID={did}, Score={sc:.2f}\")\n"
      ],
      "metadata": {
        "id": "sInvxAVwCtdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b49683-ce7b-4ef6-e051-693d0b0ae127"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method=1, first 5 results:\n",
            "  DocID=2, Score=0.00\n",
            "  DocID=3, Score=0.00\n",
            "  DocID=4, Score=0.00\n",
            "  DocID=6, Score=0.00\n",
            "  DocID=12, Score=0.00\n",
            "Method=2, first 5 results:\n",
            "  DocID=469, Score=43.51\n",
            "  DocID=456, Score=38.03\n",
            "  DocID=1030, Score=35.77\n",
            "  DocID=599, Score=34.54\n",
            "  DocID=85, Score=34.50\n",
            "Method=3, first 5 results:\n",
            "  DocID=469, Score=5.45\n",
            "  DocID=599, Score=5.17\n",
            "  DocID=85, Score=5.03\n",
            "  DocID=456, Score=5.00\n",
            "  DocID=137, Score=5.00\n",
            "Method=4, first 5 results:\n",
            "  DocID=469, Score=43.51\n",
            "  DocID=456, Score=38.03\n",
            "  DocID=1030, Score=35.77\n",
            "  DocID=599, Score=34.54\n",
            "  DocID=85, Score=34.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main_loop (Interactive ή One-shot)\n",
        "Εδώ έχουμε τη συνάρτηση που, αν use='1', καλείται σε one-shot mode (π.χ. για αυτόματες κλήσεις όπως ground truth). Αλλιώς (default) μπαίνει σε interactive CLI mode.\n",
        "\n"
      ],
      "metadata": {
        "id": "FxHn3Zy5K8iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# main_loop (διαδραστικό ή one-shot)\n",
        "# ============================================================\n",
        "\n",
        "def main_loop(articles, title_mapping, query=None, use='0', method=None):\n",
        "    global _inverted_index\n",
        "    if use == '1':\n",
        "        # one-shot λειτουργία: δεν κάνουμε interactive\n",
        "        _inverted_index = buildInvertedIndex(articles)\n",
        "        doc_ids, scores = ranking(articles, query, method, _inverted_index)\n",
        "        return doc_ids, scores\n",
        "    else:\n",
        "        # interactive\n",
        "        while True:\n",
        "            print(\"\\nMenu:\")\n",
        "            print(\"1) Search\")\n",
        "            print(\"2) Exit\")\n",
        "            choice = input(\"Choice: \").strip()\n",
        "            if choice == '1':\n",
        "                user_query = input(\"Enter your query: \")\n",
        "                print(\"Methods:\\n1) Boolean\\n2) TF-IDF\\n3) BM25\\n4) TF-IDF + Cosine\")\n",
        "                user_method = input(\"Select (1..4): \").strip()\n",
        "                # Φτιάχνουμε/ανανέουμε το inverted_index πριν το ranking\n",
        "                _inverted_index = buildInvertedIndex(articles)\n",
        "                docs, scores = ranking(articles, user_query, user_method, _inverted_index)\n",
        "\n",
        "                top_k = min(10, len(docs))\n",
        "                for i in range(top_k):\n",
        "                    did = docs[i]\n",
        "                    sc = scores[i] if scores else 0\n",
        "                    title = title_mapping.get(did, \"No Title\")\n",
        "                    print(f\"{i+1}. DocID={did}, Score={sc:.2f}, Title={title}\")\n",
        "            elif choice == '2':\n",
        "                print(\"Exiting interactive mode.\")\n",
        "                break\n",
        "        return [], []\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Παράδειγμα: Κλήση main_loop σε One-shot mode\n",
        "# -----------------------------------------------------------\n",
        "print(\"\\n=== One-shot example ===\")\n",
        "test_q = \"information retrieval system\"\n",
        "doc_ids_test, sc_test = main_loop(articles, title_mapping, query=test_q, use='1', method='2')\n",
        "print(f\"One-shot, method=2, found {len(doc_ids_test)} docs. Top 5 doc IDs:\")\n",
        "print(doc_ids_test[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_9fFlDFIbpf",
        "outputId": "ed4587b0-7e0a-48b6-e88b-5e5bcf695879"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== One-shot example ===\n",
            "One-shot, method=2, found 846 docs. Top 5 doc IDs:\n",
            "[565, 1136, 459, 458, 538]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ground Truth Creation & Parse Relevance\n",
        "Δημιουργία Ground Truth (CISI.REL)\n"
      ],
      "metadata": {
        "id": "YV5ThGqWLH0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Ground Truth creation (CISI.REL)\n",
        "# ============================================================\n",
        "\n",
        "def ground_truth(articles, title_mapping, queries, method_for_gt='3'):\n",
        "    \"\"\"\n",
        "    Δημιουργεί/ενημερώνει το αρχείο CISI.REL με μορφή:\n",
        "      query_id doc_id relevance score\n",
        "    όπου η relevance καθορίζεται από thresholds στο score.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for qid, qtext in queries.items():\n",
        "        # Καλούμε main_loop σε one-shot mode με τη ζητούμενη μέθοδο\n",
        "        ranked_docs, scores = main_loop(articles, title_mapping, qtext, use='1', method=method_for_gt)\n",
        "        query_data = []\n",
        "        for doc_id, sc in zip(ranked_docs, scores):\n",
        "            # Παράδειγμα thresholding\n",
        "            if sc < 10:\n",
        "                relevance = 0\n",
        "            elif 10 <= sc < 30:\n",
        "                relevance = 1\n",
        "            else:\n",
        "                relevance = 2\n",
        "            query_data.append((qid, doc_id, relevance, sc))\n",
        "        data.extend(query_data)\n",
        "\n",
        "    # Γράφουμε σε CISI.REL\n",
        "    with open(\"./CISI.REL\", \"w\") as f:\n",
        "        for row in data:\n",
        "            f.write(\"{:5d} {:5d} {:1d} {:10.4f}\\n\".format(row[0], row[1], row[2], row[3]))\n",
        "    print(\"CISI.REL updated successfully.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Παράδειγμα: Δημιουργούμε ground truth με μέθοδο BM25\n",
        "# -----------------------------------------------------------\n",
        "print(\"Creating ground truth (CISI.REL) with method=3 (BM25) ...\")\n",
        "ground_truth(articles, title_mapping, queries, method_for_gt='3')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M3tNbwDLJzQ",
        "outputId": "e0d9a8b7-2b84-4aa4-80c3-28013a17f2b4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating ground truth (CISI.REL) with method=3 (BM25) ...\n",
            "CISI.REL updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse Relevance (διαβάζει CISI.REL)"
      ],
      "metadata": {
        "id": "v6N4at-4LVl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Parse Relevance\n",
        "# ============================================================\n",
        "\n",
        "def parse_relevance(file_path):\n",
        "    \"\"\"\n",
        "    Διαβάζει το CISI.REL και φτιάχνει ένα λεξικό:\n",
        "      { query_id: [doc_ids με rel>0] }\n",
        "    \"\"\"\n",
        "    relevance_dict = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 3:\n",
        "                qid = int(parts[0])\n",
        "                did = int(parts[1])\n",
        "                rel = int(parts[2])\n",
        "                if qid not in relevance_dict:\n",
        "                    relevance_dict[qid] = []\n",
        "                if rel > 0:\n",
        "                    relevance_dict[qid].append(did)\n",
        "    return relevance_dict\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή\n",
        "# -----------------------------------------------------------\n",
        "rel_dict = parse_relevance(\"./CISI.REL\")\n",
        "print(f\"Parsed relevance from CISI.REL: found {len(rel_dict)} queries with rel>0 info.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0c7vmgSLNwZ",
        "outputId": "52e85daa-effb-4312-f690-a64c682da569"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed relevance from CISI.REL: found 57 queries with rel>0 info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Search Engine (Precision, Recall, F1)\n",
        "Τέλος, δείχνουμε πώς να κάνουμε evaluation χρησιμοποιώντας το ground truth που δημιουργήσαμε:\n",
        "\n"
      ],
      "metadata": {
        "id": "0P37ntc_Ld51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Evaluate Search Engine\n",
        "# ============================================================\n",
        "\n",
        "def eval_search_engine(queries, ground_truth_dict, articles, title_mapping):\n",
        "    \"\"\"\n",
        "    Κάνει Evaluation με precision, recall, F1.\n",
        "    Ζητάει μέθοδο (1..4), μετά για κάθε query:\n",
        "      - τρέχει main_loop (one-shot)\n",
        "      - υπολογίζει tp, fp, fn\n",
        "    \"\"\"\n",
        "    print(\"\\nSelect Ranking Method for Evaluation:\")\n",
        "    print(\"1) Boolean Search\")\n",
        "    print(\"2) TF-IDF (dot product)\")\n",
        "    print(\"3) Okapi BM25\")\n",
        "    print(\"4) TF-IDF + Cosine Similarity\")\n",
        "    method_choice = input(\"Enter your choice (1/2/3/4): \").strip()\n",
        "\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for qid, qtext in queries.items():\n",
        "        print(f\"\\nEvaluating Query ID {qid}: {qtext}\")\n",
        "        doc_ids, _scores = main_loop(articles, title_mapping, qtext, use='1', method=method_choice)\n",
        "        retrieved_docs = set(doc_ids)\n",
        "        relevant_docs = set(ground_truth_dict.get(qid, []))\n",
        "\n",
        "        tp = len(retrieved_docs & relevant_docs)\n",
        "        fp = len(retrieved_docs - relevant_docs)\n",
        "        fn = len(relevant_docs - retrieved_docs)\n",
        "\n",
        "        precision = tp/(tp+fp) if (tp+fp) > 0 else 0\n",
        "        recall = tp/(tp+fn) if (tp+fn) > 0 else 0\n",
        "        f1 = 2*precision*recall/(precision+recall) if (precision+recall) > 0 else 0\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")\n",
        "\n",
        "    avg_p = sum(precision_scores)/len(precision_scores) if precision_scores else 0\n",
        "    avg_r = sum(recall_scores)/len(recall_scores) if recall_scores else 0\n",
        "    avg_f1 = sum(f1_scores)/len(f1_scores) if f1_scores else 0\n",
        "\n",
        "    print(\"\\nOverall Performance:\")\n",
        "    print(f\"Avg Precision: {avg_p:.2f}\")\n",
        "    print(f\"Avg Recall:    {avg_r:.2f}\")\n",
        "    print(f\"Avg F1-Score:  {avg_f1:.2f}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# Δοκιμή evaluation\n",
        "# -----------------------------------------------------------\n",
        "print(\"\\n=== Evaluate Search Engine ===\")\n",
        "ground_truth_dict = parse_relevance(\"./CISI.REL\")\n",
        "eval_search_engine(queries, ground_truth_dict, articles, title_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uflTt4HTLZou",
        "outputId": "7344ddfa-e4be-4e3f-cd16-f4384c69cd84"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluate Search Engine ===\n",
            "\n",
            "Select Ranking Method for Evaluation:\n",
            "1) Boolean Search\n",
            "2) TF-IDF (dot product)\n",
            "3) Okapi BM25\n",
            "4) TF-IDF + Cosine Similarity\n",
            "Enter your choice (1/2/3/4): 3\n",
            "\n",
            "Evaluating Query ID 1: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "Precision=0.12, Recall=1.00, F1=0.21\n",
            "\n",
            "Evaluating Query ID 2: How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?\n",
            "Precision=0.03, Recall=1.00, F1=0.07\n",
            "\n",
            "Evaluating Query ID 3: What is information science?  Give definitions where possible.\n",
            "Precision=0.00, Recall=1.00, F1=0.01\n",
            "\n",
            "Evaluating Query ID 4: Image recognition and any other methods of automatically transforming printed text into computer-ready form.\n",
            "Precision=0.02, Recall=1.00, F1=0.04\n",
            "\n",
            "Evaluating Query ID 5: What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems? What problems are they likely to encounter?\n",
            "Precision=0.05, Recall=1.00, F1=0.10\n",
            "\n",
            "Evaluating Query ID 6: What possibilities are there for verbal communication between computers and humans, that is, communication via the spoken word?\n",
            "Precision=0.01, Recall=1.00, F1=0.03\n",
            "\n",
            "Evaluating Query ID 7: Describe presently working and planned systems for publishing and printing original papers by computer, and then saving the byproduct, articles coded in data-processing form, for further use in retrieval.\n",
            "Precision=0.07, Recall=1.00, F1=0.14\n",
            "\n",
            "Evaluating Query ID 8: Describe information retrieval and indexing in other languages. What bearing does it have on the science in general?\n",
            "Precision=0.02, Recall=1.00, F1=0.03\n",
            "\n",
            "Evaluating Query ID 9: What possibilities are there for automatic grammatical and contextual analysis of articles for inclusion in an information retrieval system?\n",
            "Precision=0.02, Recall=1.00, F1=0.03\n",
            "\n",
            "Evaluating Query ID 10: The use of abstract mathematics in information retrieval, e.g. group theory.\n",
            "Precision=0.01, Recall=1.00, F1=0.02\n",
            "\n",
            "Evaluating Query ID 11: What is the need for information consolidation, evaluation, and retrieval in scientific research?\n",
            "Precision=0.00, Recall=1.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 12: Give methods for high speed publication, printing, and distribution of scientific journals.\n",
            "Precision=0.02, Recall=1.00, F1=0.04\n",
            "\n",
            "Evaluating Query ID 13: What criteria have been developed for the objective evaluation of information retrieval and dissemination systems?\n",
            "Precision=0.01, Recall=1.00, F1=0.03\n",
            "\n",
            "Evaluating Query ID 14: What future is there for automatic medical diagnosis?\n",
            "Precision=0.00, Recall=0.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 15: How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "Precision=0.03, Recall=1.00, F1=0.05\n",
            "\n",
            "Evaluating Query ID 16: What systems incorporate multiprogramming or remote stations in information retrieval?  What will be the extent of their use in the future?\n",
            "Precision=0.00, Recall=1.00, F1=0.01\n",
            "\n",
            "Evaluating Query ID 17: Means of obtaining large volume, high speed, customer usable information retrieval output.\n",
            "Precision=0.01, Recall=1.00, F1=0.01\n",
            "\n",
            "Evaluating Query ID 18: What methods are there for encoding, automatically matching, and automatically drawing structures extended in two dimensions, like the structural formulas for chemical compounds?\n",
            "Precision=0.11, Recall=1.00, F1=0.19\n",
            "\n",
            "Evaluating Query ID 19: Techniques of machine matching and machine searching systems. Coding and matching methods.\n",
            "Precision=0.05, Recall=1.00, F1=0.10\n",
            "\n",
            "Evaluating Query ID 20: Testing automated information systems.\n",
            "Precision=0.00, Recall=0.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 21: The need to provide personnel for the information field.\n",
            "Precision=0.00, Recall=0.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 22: Automated information in the medical field.\n",
            "Precision=0.00, Recall=0.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 23: Amount of use of books in libraries. Relation to need for automated information systems .\n",
            "Precision=0.01, Recall=1.00, F1=0.02\n",
            "\n",
            "Evaluating Query ID 24: Educational and training requirements for personnel in the information field. Possibilities for this training.  Needs for programs providing this training.\n",
            "Precision=0.04, Recall=1.00, F1=0.08\n",
            "\n",
            "Evaluating Query ID 25: International systems for exchange and dissemination of information.\n",
            "Precision=0.00, Recall=1.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 26: Cost and determination of cost associated with systems of automated information.\n",
            "Precision=0.03, Recall=1.00, F1=0.05\n",
            "\n",
            "Evaluating Query ID 27: Computerized information retrieval systems.  Computerized indexing systems.\n",
            "Precision=0.03, Recall=1.00, F1=0.05\n",
            "\n",
            "Evaluating Query ID 28: Computerized information systems in fields related to chemistry.\n",
            "Precision=0.00, Recall=1.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 29: Specific advantages of computerized index systems.\n",
            "Precision=0.00, Recall=1.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 30: Information dissemination by journals and periodicals.\n",
            "Precision=0.00, Recall=1.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 31: Information systems in the physical sciences.\n",
            "Precision=0.00, Recall=0.00, F1=0.00\n",
            "\n",
            "Evaluating Query ID 32: Attempts at computerized and mechanized systems for general libraries. Problems and methods of automated general author and title indexing systems.\n",
            "Precision=0.07, Recall=1.00, F1=0.13\n",
            "\n",
            "Evaluating Query ID 33: Retrieval systems which provide for the automated transmission of information to the user from a distance.\n",
            "Precision=0.01, Recall=1.00, F1=0.02\n",
            "\n",
            "Evaluating Query ID 34: Methods of coding used in computerized index systems.\n",
            "Precision=0.00, Recall=1.00, F1=0.01\n",
            "\n",
            "Evaluating Query ID 35: Government supported agencies and projects dealing with information dissemination.\n",
            "Precision=0.01, Recall=1.00, F1=0.02\n",
            "\n",
            "Evaluating Query ID 36: What are some of the theories and practices in computer translating of texts from one national language to another?  How can machine translating compete with traditional methods of translating in comprehending nuances of meaning in languages of different structures?\n",
            "Precision=0.10, Recall=1.00, F1=0.18\n",
            "\n",
            "Evaluating Query ID 37: What lists of words useful for indexing or classifying material are available?  Wanted are lists of terms that are descriptive vocabularies of particular fields or schedules of words that are related to each other in meaningful schemes.  Wanted are lists that have been tested, at least to some extent, and found useful for organizing material and for retrieving it.\n",
            "Precision=0.24, Recall=1.00, F1=0.39\n",
            "\n",
            "Evaluating Query ID 38: How can access words in an information retrieval system be kept up to date? Word meanings and usage often change and lists must be dynamic to be current. What definitions of the problem and progress toward solutions have been made in providing necessary flexibility in systems of subject headings, index words, or other symbols used for getting at stored data?\n",
            "Precision=0.29, Recall=1.00, F1=0.44\n",
            "\n",
            "Evaluating Query ID 39: The progress of information retrieval presents problems of maladjustment and dislocation of personnel.  Training and retraining of people to use the new equipment is important at all levels.  Librarians, assistants, technicians, students, researchers, and even executives will need education to learn the purpose, values, and uses of information systems and hardware. What programs have been developed to change the attitudes and skills of traditional workers and help them to learn the newer techniques?\n",
            "Precision=0.35, Recall=1.00, F1=0.52\n",
            "\n",
            "Evaluating Query ID 40: What is the status of machine translation?  What progress has been made in the use of computers to transfer from one language to another with some degree of automation?  What problems and stumbling blocks have been found and are they considered to be insurmountable limitations or only challenging to the field of documentation on an international scale?\n",
            "Precision=0.09, Recall=1.00, F1=0.16\n",
            "\n",
            "Evaluating Query ID 41: Is alphabetical ordering of material considered to be a useful tool in information retrieval?  What studies have been done to compare the effectiveness of alphabetical order with other organization schemes? Is there a generally accepted form of arranging material in alphabetical order, and is there an easy way of achieving this form without going to a great amount of effort?\n",
            "Precision=0.22, Recall=1.00, F1=0.37\n",
            "\n",
            "Evaluating Query ID 42: The average student or researcher has difficulty in comprehending the vocabulary of information retrieval.  It appears important that this new field be understood before it is to be fully accepted.  What basic articles would provide an understanding of the various important aspects of the information storage and retrieval?\n",
            "Precision=0.20, Recall=1.00, F1=0.33\n",
            "\n",
            "Evaluating Query ID 43: The difficulties encountered in information retrieval systems are often less related to the equipment used than to the failure to plan adequately for document analysis, indexing, and machine coding.  The position of the programmer is to take a problem and write it in a way in which the equipment will understand.  What articles have been written describing research in maximizing the effectiveness of programming?\n",
            "Precision=0.26, Recall=1.00, F1=0.41\n",
            "\n",
            "Evaluating Query ID 44: There are presently fifty to one hundred technical journals being published.  On the average, two new journals appear every day.  In the many journals published, one to two million articles appear every year.  What attempts have been made to cope with this amount of scientific and technical publication in terms of analysis, control, storage, and retrieval?\n",
            "Precision=0.35, Recall=1.00, F1=0.51\n",
            "\n",
            "Evaluating Query ID 45: I am looking for information about the impact of automation on libraries and its significance for libraries in general.  This includes the increasing importance of automation in view of the proliferation of information today, and how automation can help libraries cope with this problem.  How will automation affect libraries and how should they react to the idea of automation?\n",
            "Precision=0.21, Recall=1.00, F1=0.35\n",
            "\n",
            "Evaluating Query ID 46: I am seeking information on the use of data processing in libraries and the mechanization of routine library processes and procedures.  I would like descriptions of both general and specific applications of automation in such areas as circulation, cataloging, acquisitions, serial records, and other record-keeping.  Examples should be based on the operation of a conventional public or university library, or practices in a special library which could also be applied in a public or university library.  Give descriptions of equipment and operations, both present and projected.\n",
            "Precision=0.57, Recall=1.00, F1=0.73\n",
            "\n",
            "Evaluating Query ID 47: Is there any established means at present for an international exchange of material about information retrieval?  If there is, does it take the form of an international agency or center which regularly distributes information retrieval methods and research results?  If there is not, in what ways has this material crossed national boundaries?  What seem to have been some of the problems blocking a better international exchange, and is any effort being made to solve some of those problems?\n",
            "Precision=0.32, Recall=1.00, F1=0.48\n",
            "\n",
            "Evaluating Query ID 48: Information retrieval is still such a new and experimental field that a line distinguishing research and practice is often difficult - even impossible - to draw.  Are there, however, actual centers of research on information retrieval?  If so, in which countries are they located?  Who supports them - government, business, universities, or libraries?  Can information retrieval as a specialized research discipline be said to be emerging, or is it still an amalgam of skills from other fields, such as mathematics, engineering, and library science?  In other words, tell me about information retrieval research.\n",
            "Precision=0.53, Recall=1.00, F1=0.69\n",
            "\n",
            "Evaluating Query ID 49: Most resources have been spent on applying information retrieval techniques to the physical and medical sciences.  But, has information retrieval been used at all in the natural sciences, social sciences, and humanities?  If so, what have been some of the problems which have been encountered with these subject areas and how have they been solved, if at all?  Have the characteristics of these subject areas necessitated the development of new information retrieval techniques? What are the prospcts for future machine control in these areas?\n",
            "Precision=0.45, Recall=1.00, F1=0.62\n",
            "\n",
            "Evaluating Query ID 50: Is there any use for traditional classification schemes - DDC, UDC, LC, etc. - in information retrieval systems?  If there is, which scheme appears most suited to machine use and where has it been applied? If there is not, why are these classification schemes irrelevant? Has research shown that a subject classification of knowledge is completely unnecessary in machine systems? Or, have new schemes been devised which appear to be more suited to machine use?\n",
            "Precision=0.25, Recall=1.00, F1=0.41\n",
            "\n",
            "Evaluating Query ID 51: Coordinate indexing utilizes descriptors for controlled language.  Of what use are descriptors in the construction of an index?  How can descriptors be used for searching in an information retrieval system?\n",
            "Precision=0.12, Recall=1.00, F1=0.22\n",
            "\n",
            "Evaluating Query ID 52: What are the characteristics of MEDLARS (Medical Literature Analysis and Retrieval System) project which has been undertaken by the National Library of Medicine?  How does it index current medical journals and of what relation is this indexing system to Index Medicus? What are the major components of the MEDLARS project and its major operating details?\n",
            "Precision=0.29, Recall=1.00, F1=0.45\n",
            "\n",
            "Evaluating Query ID 53: How can the computer be used in medical science for diagnostic and clinical record keeping purposes?  Have any programs of automation been tried in hospitals?  If so, what have been the results? What problems have been encountered in the use of automation in medicine?  For what purposes can an automated system of clinical records be used?  What are other possible uses of the computer in medicine?\n",
            "Precision=0.23, Recall=1.00, F1=0.38\n",
            "\n",
            "Evaluating Query ID 54: What is the effect on librarians of automation?  Note the new types of technology to be used in the library which will have an effect on the status, position, and function of the librarians.  What changes are being contemplated or have been initiated to introduce automation into the education of librarians?\n",
            "Precision=0.14, Recall=1.00, F1=0.25\n",
            "\n",
            "Evaluating Query ID 55: What are the aims and objectives of the medical literature analysis and retrieval system (MEDLARS)?  How does MEDLARS operate?  What are the possible applications of MEDLARS to future information retrieval systems?\n",
            "Precision=0.12, Recall=1.00, F1=0.22\n",
            "\n",
            "Evaluating Query ID 56: The standard method of finding information in today's libraries is through the use of the alphabetically arranged card catalog or the classified catalog based on a classification system such as the DC or LC.  Can these systems be modified for use with automated information retrieval?\n",
            "Precision=0.20, Recall=1.00, F1=0.33\n",
            "\n",
            "Evaluating Query ID 57: In catalogs which are either arranged alphabetically or arranged by classification number, the LC entry, printed in readable language, is ultimately important because the individual looking for information has a definite author, title, or subject phrase in his language (probably English in our case) in mind.  Will LC entries and subject headings be used in the same manner in automated systems?\n",
            "Precision=0.21, Recall=1.00, F1=0.35\n",
            "\n",
            "Overall Performance:\n",
            "Avg Precision: 0.11\n",
            "Avg Recall:    0.91\n",
            "Avg F1-Score:  0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6bYvntSLhpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}